{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn import metrics\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Model development below\n",
    "Code is scattered, but the goal is to build a run_model function that takes in data, data type, and drug and returns single table comparing all models. Then the goal will be to iterate through data type combos and drugs and come up with a complete analysis output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from load_data import AMLData, cluster_colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# point of access for all data\n",
    "data = AMLData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drugs_to_focus = [\n",
    "    'Panobinostat',\n",
    "    'Gilteritinib',\n",
    "    'Venetoclax',\n",
    "    'Sorafenib',\n",
    "    'Quizartinib (AC220)',\n",
    "    'Trametinib (GSK1120212)',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data.auc_table[drugs_to_focus].dropna(subset=['Venetoclax', 'Panobinostat', 'Sorafenib'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "node_labels = data.meta['Cluster']\n",
    "node_labels.dropna(inplace=True)\n",
    "\n",
    "node_lut = dict(zip(sorted(node_labels.unique()), cluster_colors))\n",
    "\n",
    "node_colors = pd.Series(node_labels, index=data.meta.index.values, name='Cluster').map(node_lut)\n",
    "handles = [Patch(facecolor=node_lut[name]) for name in node_lut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "table = data.auc_table[data.drug_names].copy()\n",
    "\n",
    "\n",
    "# at least 100 samples\n",
    "drug_counts = table.describe().T['count']\n",
    "high_occ_drugs = drug_counts[drug_counts > 100].index.values\n",
    "\n",
    "counts = table[table < 100].count()\n",
    "responsive_drugs = counts[counts > 10].index.values\n",
    "# only run single drugs for now\n",
    "drug_solo = [i for i in responsive_drugs if ' - ' not in i]\n",
    "\n",
    "good_drugs = set(drug_solo).intersection(high_occ_drugs)\n",
    "\n",
    "# adding FLT3 inhibitors back in.\n",
    "for i in drugs_to_focus:\n",
    "    if i not in good_drugs:\n",
    "        good_drugs.add(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(len(good_drugs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def return_string(x):\n",
    "    return '|'.join([str(i) for i in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we wanted to train the model on each cluster, we would have 7-16 samples per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def score_all(y_test, preds):\n",
    "    error = np.sqrt(metrics.mean_squared_error(y_test, preds))\n",
    "    r2 = metrics.r2_score(y_test, preds)\n",
    "    pearson, pr = pearsonr(y_test, preds)\n",
    "    spearman, sr = spearmanr(y_test, preds)\n",
    "    return error, r2, pearson, spearman, pr, sr\n",
    "\n",
    "\n",
    "def run_subset_model(d_sets, drug_name, flt3_only=False, \n",
    "                     non_flt3_only=False, cluster=None):\n",
    "    \n",
    "    ds = data.get_trainable_data(d_sets, drug_name,\n",
    "                                 new_format=True,\n",
    "                                 flt3_only=flt3_only, \n",
    "                                 non_flt3_only=non_flt3_only,\n",
    "                                 cluster=cluster)\n",
    "    \n",
    "    print(f\"Feature size : {ds.features.shape}\")\n",
    "    \n",
    "    args = [ds, True]\n",
    "    results = pd.DataFrame([run_lgmb(*args)])\n",
    "    \n",
    "    if isinstance(d_sets, str):\n",
    "        out_name = d_sets\n",
    "    else:\n",
    "        out_name = '_'.join(sorted(d_sets))\n",
    "        \n",
    "    results['source_data'] = out_name\n",
    "    results['drug_name'] = drug_name\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parameters = dict(\n",
    "    device_type='cpu',\n",
    "    boosting_type='gbdt',\n",
    "    num_threads=8,\n",
    "    n_jobs=None,\n",
    "    objective='regression',\n",
    "    metric='rmse',\n",
    "    lambda_l1=1000,\n",
    "    lambda_l2=1,\n",
    "    reg_alpha=None,\n",
    "    reg_lambda=None,\n",
    "    learning_rate=.1,\n",
    "    tree_learner='serial',\n",
    "    max_bin=128,\n",
    "    num_leaves=5,\n",
    "    max_depth=-1,\n",
    "\n",
    "    feature_fraction=1,  # .8\n",
    "\n",
    "    bagging_freq=1,\n",
    "    bagging_fraction=.8,\n",
    "    subsample=None,\n",
    "    subsample_freq=None,\n",
    "\n",
    "    min_child_weight=0.2,\n",
    "    min_data_in_leaf=2,\n",
    "    min_child_samples=None,\n",
    "    min_gain_to_split=None,\n",
    "    colsample_bytree=None,\n",
    "    min_split_gain=None,\n",
    "    n_estimators=10000,\n",
    "    verbose=-1,\n",
    "    deterministic=True,\n",
    "    random_state=10,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_lgmb(ds, plot=False):\n",
    "\n",
    "     \n",
    "    x_train, x_test, y_train, y_test = ds.train_test_split()\n",
    "    x_train, y_train = ds.features, ds.target\n",
    "    feature_names = list(set(ds.features.columns.values))\n",
    "    model_name = 'gbt2'\n",
    "    \n",
    "    lgb_model = LGBMRegressor(**parameters)\n",
    "    lgb_model.fit(x_train, y_train)\n",
    "    \n",
    "    feats = pd.Series(lgb_model.feature_importances_, index=feature_names)\n",
    "    feats.sort_values(inplace=True, ascending=False)\n",
    "\n",
    "    selected_feat = feats[feats > 0].index.values\n",
    "    scores = feats[feats > 0]\n",
    "\n",
    "    preds = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration_)\n",
    "    error, r2, pearson, spearman, pr, sr = score_all(y_test, preds)\n",
    "    \n",
    "    \n",
    "    if plot:\n",
    "        train_pred = lgb_model.predict(x_train, num_iteration=lgb_model.best_iteration_)\n",
    "        sns.regplot(y_test, preds, label='test')\n",
    "        sns.regplot(y_train, train_pred, label='train')\n",
    "        plt.title(\"GBT\")\n",
    "        plt.xlabel(\"Actual\")\n",
    "        plt.ylabel(\"Predicted\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'feature_names': list(selected_feat),\n",
    "        'feature_scores':list(scores.values),\n",
    "        'n_feat': len(selected_feat),\n",
    "        'mae': error,\n",
    "        'r2': r2,\n",
    "        'pearson': pearson,\n",
    "        'spearman': spearman,\n",
    "        'pr': pr,\n",
    "        'sr': sr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = run_subset_model(['proteomics', 'phospho'], 'Venetoclax')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_all():\n",
    "    data_sources = [\n",
    "        'proteomics',\n",
    "        'rna_seq',\n",
    "        'phospho',\n",
    "        'wes',\n",
    "        ['proteomics', 'phospho'],\n",
    "        ['proteomics', 'rna_seq'],\n",
    "        ['proteomics', 'wes'],\n",
    "\n",
    "        ['phospho', 'rna_seq'],\n",
    "        ['phospho', 'wes'],\n",
    "        ['rna_seq', 'wes'],\n",
    "\n",
    "        ['proteomics', 'phospho', 'wes'],\n",
    "        ['rna_seq', 'phospho', 'wes'],\n",
    "        ['proteomics', 'phospho', 'rna_seq'],\n",
    "        ['proteomics', 'wes', 'rna_seq'],\n",
    "\n",
    "        ['proteomics', 'phospho', 'rna_seq', 'wes'],\n",
    "    ]\n",
    "\n",
    "    all_results = []\n",
    "    for i in reversed(sorted(drug_subset)):\n",
    "        print(f\"Working on {i}\")\n",
    "        for j in data_sources:\n",
    "            all_results.append(run_subset_model(j, i))\n",
    "    all_results = pd.concat(all_results, ignore_index=True)\n",
    "    all_results.feature_names = all_results.feature_names.str.join('|')\n",
    "    all_results.feature_scores = all_results.feature_scores.apply(return_string)\n",
    "    all_results.to_csv('gbt_all_drugs_full_data_model_features_final.csv', )\n",
    "    all_results.head()\n",
    "# run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_sources = [['proteomics', 'phospho']]\n",
    "\n",
    "drug_subset = ['Sorafenib', 'Panobinostat', 'Venetoclax']\n",
    "\n",
    "all_results = []\n",
    "for i in reversed(sorted(drug_subset)):\n",
    "    print(f\"Working on {i}\")\n",
    "    for j in data_sources:\n",
    "        all_results.append(run_subset_model(j, i))\n",
    "all_results = pd.concat(all_results, ignore_index=True)\n",
    "all_results.feature_names = all_results.feature_names.str.join('|')\n",
    "all_results.feature_scores = all_results.feature_scores.apply(return_string)\n",
    "all_results.to_csv('gbt_full_data_select_drugs.csv', )\n",
    "all_results.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}